{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.rc('figure',figsize=(17,13))\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\nfrom plotly.subplots import make_subplots\npyo.init_notebook_mode()\n\n\nimport re\nimport string \n\nimport nltk\nfrom nltk.probability import FreqDist\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom nltk import pos_tag\nfrom nltk.tokenize import word_tokenize\n\nfrom wordcloud import WordCloud\nfrom tqdm.auto import tqdm","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('tweets.csv')\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Rows              :',df.shape[0])\nprint('Columns           :',df.shape[1])\nprint('\\nFeatures        :\\n',df.columns.tolist())\nprint('\\nMissing values  :',df.isna().sum().values.sum())\nprint('\\nUnique values   :',df.nunique())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \nanalyser=SentimentIntensityAnalyzer()\nscores=[]\nfor i in range(len(df['text'])):\n    score=analyser.polarity_scores(df['text'][i])\n    score=score['compound']\n    scores.append(score)\nsentiment=[]\nfor i in scores:\n    if i>=0.05:\n        sentiment.append('Positive')\n    elif i<=(-0.05):\n        sentiment.append('Negative')\n    else:\n        sentiment.append('Neutral')\ndf['sentiment']=pd.Series(np.array(sentiment))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA) ","metadata":{}},{"cell_type":"code","source":"# Sentiment count\ntemp=df.groupby('sentiment')['text'].count().reset_index().sort_values(by='sentiment',ascending=False)\ntemp.style.background_gradient(cmap='Blues')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(df['sentiment'])\nplt.title('sentiment Distribution',fontsize=20)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Account Verified / Not verified\n\nplt.figure(figsize=(12,6))\nsns.countplot(df['user_verified'])\nplt.title('Account Distribution',fontsize=20)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution of the favoutires recieved based on tweets sentiment and whether the account is verified/Not","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.barplot(x='user_verified',y='user_favourites',hue='sentiment',data=df)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The Top 30 Most Hashtags in the tweet text data","metadata":{}},{"cell_type":"code","source":"df['hashtags']=df['hashtags'].fillna('[]')\n\nall_hashtags=[]\nfor i in range(len(df['hashtags'])):\n    a=df['hashtags'][i].strip('][').split(',')\n    for i in a:\n        all_hashtags.append(i)\nall_hashtags=['No hashtags' if x=='' else x for x in all_hashtags]\n\nall_hashtags=pd.Series(np.array(all_hashtags))\nprint('There are {} instances of tweets in which No hashtags were used'.format(all_hashtags.value_counts()[1]))\n\ncommon_hashtags=all_hashtags.value_counts().drop(labels='No hashtags')[:30].rename_axis('Common Hashtags').reset_index(name='count')\nfig=px.treemap(common_hashtags,path=['Common Hashtags'],values='count',title='Top 30 Common Hashtags')\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sentiment wise analysis of hashtags and words","metadata":{}},{"cell_type":"code","source":"positive_tweet=df[df['sentiment']=='Positive'].reset_index()\nnegative_tweet=df[df['sentiment']=='Negative'].reset_index()\nneutral_tweet=df[df['sentiment']=='Neutral'].reset_index()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# POSITIVE TWEETS\nall_positive_words=[]\nall_positive_hashtags=[]\nfor i in range(len(positive_tweet['text'])):\n    a=positive_tweet['text'][i]\n    b=positive_tweet['hashtags'][i].strip('][').split(', ')\n    for i in a:\n        all_positive_words.append(i)\n    for i in b:\n        all_positive_hashtags.append(i)\n\nall_positive_words=pd.Series(np.array(all_positive_words))\nall_positive_hashtags=pd.Series(np.array(all_positive_hashtags))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_negative_words=[]\nall_negative_hashtags=[]\nfor i in range(len(negative_tweet['text'])):\n    a=negative_tweet['text'][i]\n    b=negative_tweet['hashtags'][i].strip('][').split(', ')\n    for i in a:\n        all_negative_words.append(i)\n    for i in b:\n        all_negative_hashtags.append(i)\nall_negative_words=pd.Series(np.array(all_negative_words))\nall_negative_hashtags=pd.Series(np.array(all_negative_hashtags))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_neutral_words=[]\nall_neutral_hashtags=[]\nfor i in range(len(neutral_tweet['text'])):\n    a=neutral_tweet['text'][i]\n    b=neutral_tweet['hashtags'][i].strip('][').split(', ')\n    for i in a:\n        all_neutral_words.append(i)\n    for i in b:\n        all_neutral_hashtags.append(i)\nall_neutral_words=pd.Series(np.array(all_neutral_words))\nall_neutral_hashtags=pd.Series(np.array(all_neutral_hashtags))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common=set(all_positive_words).intersection(set(all_negative_words)).intersection(set(all_neutral_words))\ncommon_list=list(common)\n\ncommon_words=all_negative_words.value_counts().drop(labels=common_list)[:30].rename_axis('common negative words').reset_index(name='count')\nfig=px.treemap(common_words,path=['common negative words'],values='count',title='Top 30 Unique words in negative Tweets')\nfig.show()\n\ncommon_words=all_positive_words.value_counts().drop(labels=common_list)[:30].rename_axis('common positive words').reset_index(name='count')\nfig=px.treemap(common_words,path=['common positive words'],values='count',title='TOp 30 Unique words in Positive Tweets')\nfig.show()\n\ncommon_words=all_neutral_words.value_counts().drop(labels=common_list)[:30].rename_axis('common neutral words').reset_index(name='count')\nfig=px.treemap(common_words,path=['common neutral words'],values='count',title='Top 30 Unique words in neutral Tweets')\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Source Distribution of Tweets","metadata":{}},{"cell_type":"code","source":"data_=df['source'].value_counts().reset_index()\n\ntrace1=go.Bar(x=['Twitter Web App', 'Twitter for iPhone', 'Twitter for Android','LinkedIn', 'HubSpot', 'IFTTT', \n                 'Hypefury', 'Sprout Social','Revive Social App', 'Buffer'],\n              y=data_['source'],marker=dict(color='rgb(250,13,92)',\n              line=dict(color='rgb(0,0,0)',width=1.5)),text=data_['source'],textposition='outside')\n\nlayout=go.Layout(template='plotly_dark',title='Top 10 Most Source Disrtibution Of Tweets',xaxis=dict(title='Source'),\n                 yaxis=dict(title='Count'),height=700)\nfig=go.Figure(data=[trace1],layout=layout)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here new feature \"sentiment\" is created. corresponding to each tweet text.","metadata":{}},{"cell_type":"markdown","source":"### Here new feature \"sentiment\" is created. corresponding to each tweet text.","metadata":{}},{"cell_type":"markdown","source":"### Verified Account of Tweet","metadata":{}},{"cell_type":"code","source":"data_verified=df[df['user_verified']==True].reset_index()\ndata_not_verified=df[df['user_verified']==False].reset_index()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_=data_verified['source'].value_counts().reset_index()\n\ntrace1=go.Bar(x=['Twitter Web App', 'Twitter for iPhone', 'Twitter for Android','LinkedIn', 'HubSpot', 'IFTTT', \n                 'Hypefury', 'Sprout Social','Revive Social App', 'Buffer',],y=data_['source'],\n            marker=dict(color='rgb(250,13,92)',line=dict(color='rgb(0,0,0)',width=1.5)),text=data_['source'],\n             textposition='outside')\nlayout=go.Layout(template='plotly_dark',title='Top 20 Most Source Distribution of Twwets From Verified Accounts',xaxis=dict(title='Source'),\n                yaxis=dict(title='Count'),height=650)\nfig=go.Figure(data=[trace1],layout=layout)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_hashtags=[]\nfor i in range(len(data_verified['hashtags'])):\n    a=data_verified['hashtags'][i].strip('][').split(', ')\n    for i in a:\n        all_hashtags.append(i)\nall_hashtags=pd.Series(np.array(all_hashtags))\ncommon_hashtags=all_hashtags.value_counts()[:30].rename_axis('common hashtags').reset_index(name='count')\nfig=px.treemap(common_hashtags,path=['common hashtags'],values='count',title='30 Most common hashtags by Verified Accounts')\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tweets Sentiment Analysis Based on Location","metadata":{}},{"cell_type":"code","source":"df['user_location']=df['user_location'].fillna('')\n\npostive_tweet=df[df['sentiment']=='Positive'].reset_index()\nnegative_tweet=df[df['sentiment']=='Negative'].reset_index()\nneutral_tweet=df[df['sentiment']=='Neutral'].reset_index()\n\npos_location=positive_tweet['user_location']\nneg_location=negative_tweet['user_location']\nneu_location=neutral_tweet['user_location']\n\ncommon=set(pos_location).intersection(set(neg_location)).intersection(set(neu_location))\ncommon_list=list(common)\n\ncommon_words=neg_location.value_counts().drop(labels=common_list)[:10].rename_axis('common negative location').reset_index(name='count')\nfig=px.treemap(common_words,path=['common negative location'],values='count',title='10 Top Unique negative Tweets Location')\nfig.show()\n\ncommon_words=pos_location.value_counts().drop(labels=common_list)[:10].rename_axis('common positive location').reset_index(name='count')\nfig=px.treemap(common_words,path=['common positive location'],values='count',title='10 Top Unique positive Location')\nfig.show()\n\ncommon_words=neu_location.value_counts().drop(labels=common_list)[:10].rename_axis('common neutral location').reset_index(name='count')\nfig=px.treemap(common_words,path=['common neutral location'],values='count',title='10 top Unique Neutral Location')\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accounts with highest followers analysis based on the tweet sentiment","metadata":{}},{"cell_type":"code","source":"fig,(ax1,ax2,ax3)=plt.subplots(3,1,figsize=(10,16))\nsns.barplot(x='user_followers',y='user_name',orient='h',ax=ax1,palette=['b'],data=df[df['sentiment']=='Positive']\\\n            .drop_duplicates(subset=['user_name'])\\\n            .sort_values(by=['user_followers'],ascending=False)[:10])\nax1.set_title('Top 10 Accounts with Highest Followers whos tweets are Positive',fontsize=19,fontweight='bold')\n\nsns.barplot(x='user_followers',y='user_name',orient='h',ax=ax2,palette=['g'],data=df[df['sentiment']=='Negative']\\\n           .drop_duplicates(subset='user_name')\\\n           .sort_values(by='user_followers',ascending=False)[:10])\nax2.set_title('Top 10 Accounts with highest Follwers whos tweets are Negative',fontsize=19,fontweight='bold')\n\nsns.barplot(x='user_followers',y='user_name',orient='h',ax=ax3,palette=['r'],data=df[df['sentiment']=='Neutral']\\\n           .drop_duplicates(subset='user_name')\\\n           .sort_values(by='user_followers',ascending=False)[:10])\nax3.set_title('Top 10 Accounts with highest follwers whos tweets are neutral',fontsize=18,fontweight='bold')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### User with more friends","metadata":{}},{"cell_type":"code","source":"df[df['user_friends'] == df['user_friends'].max()]['user_name'].iloc[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### User followers in Thounds","metadata":{}},{"cell_type":"code","source":"most_pop=df.sort_values('user_followers',ascending=False)[['user_name','user_followers']].head(12)\n\nmost_pop['user_followers1']=most_pop['user_followers']/1000\n\n\nplt.figure(figsize=(12,8))\n\nsns.barplot(data=most_pop, y='user_name',x='user_followers1',color='c')\nplt.xticks(fontsize=8,rotation=0)\nplt.yticks(fontsize=15,rotation=0)\nplt.xlabel('User followers in Thounds',fontsize=20)\nplt.ylabel('')\nplt.title('Followers',fontsize=15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning ","metadata":{}},{"cell_type":"code","source":"\ndef remove_line_breaks(text):\n    text = text.replace('\\r', ' ').replace('\\n', ' ')\n    return text\n\n#remove punctuation\ndef remove_punctuation(text):\n    re_replacements = re.compile(\"__[A-Z]+__\")  # such as __NAME__, __LINK__\n    re_punctuation = re.compile(\"[%s]\" % re.escape(string.punctuation))\n    '''Escape all the characters in pattern except ASCII letters and numbers'''\n    tokens = word_tokenize(text)\n    tokens_zero_punctuation = []\n    for token in tokens:\n        if not re_replacements.match(token):\n            token = re_punctuation.sub(\" \", token)\n        tokens_zero_punctuation.append(token)\n    return ' '.join(tokens_zero_punctuation)\n\n\ndef remove_special_characters(text):\n    text = re.sub('[^a-zA-z0-9\\s]', '', text)\n    return text\n\ndef lowercase(text):\n    text_low = [token.lower() for token in word_tokenize(text)]\n    return ' '.join(text_low)\n\ndef remove_stopwords(text):\n    stop = set(stopwords.words('english'))\n    word_tokens = nltk.word_tokenize(text)\n    text = \" \".join([word for word in word_tokens if word not in stop])\n    return text\n\ndef remove_one_character_words(text):\n    '''Remove words from dataset that contain only 1 character'''\n    text_high_use = [token for token in word_tokenize(text) if len(token)>1]      \n    return ' '.join(text_high_use)   \n    \n#%%\n# Stemming with 'Snowball stemmer\" package\ndef stem(text):\n    stemmer = nltk.stem.snowball.SnowballStemmer('english')\n    text_stemmed = [stemmer.stem(token) for token in word_tokenize(text)]        \n    return ' '.join(text_stemmed)\n\ndef lemma(text):\n    wordnet_lemmatizer = WordNetLemmatizer()\n    word_tokens = nltk.word_tokenize(text)\n    text_lemma = \" \".join([wordnet_lemmatizer.lemmatize(word) for word in word_tokens])       \n    return ' '.join(text_lemma)\n\ndef sentence_word(text):\n    word_tokens = nltk.word_tokenize(text)\n    return word_tokens\n#break paragraphs to sentence token \ndef paragraph_sentence(text):\n    sent_token = nltk.sent_tokenize(text)\n    return sent_token    \n\ndef tokenize(text):\n    \"\"\"Return a list of words in a text.\"\"\"\n    return re.findall(r'\\w+', text)\n\ndef remove_numbers(text):\n    no_nums = re.sub(r'\\d+', '', text)\n    return ''.join(no_nums)\n\ndef clean_text(text):\n    _steps = [\n    remove_line_breaks,\n    remove_one_character_words,\n    remove_special_characters,\n    lowercase,\n    remove_punctuation,\n    remove_stopwords,\n    stem,\n    remove_numbers\n]\n    for step in _steps:\n        text=step(text)\n    return text   ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text']=df['text'].astype(str)\ndf['text']=[x.replace(':',' ') for x in df['text']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['clean_text']=pd.Series([clean_text(i) for i in tqdm(df['text'])])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[:,['text','clean_text']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Most discussed terms","metadata":{}},{"cell_type":"code","source":"words=df['clean_text'].values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls=[]\nfor i in words:\n    ls.append(str(i))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,13))\nwc=WordCloud(background_color='lightblue',colormap='Set2',max_words=1000,max_font_size=200,width=1600,height=800)\nwc.generate(\" \".join(ls))\nplt.title('Most discussed terms',fontsize=20)\nplt.imshow(wc.recolor(colormap='Set2',random_state=17),alpha=0.98,interpolation='bilinear')\nplt.axis('off')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}